{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f6a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import stat\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area reference data\n",
    "area_data = pd.read_excel(r'C:\\Users\\JeevaNithi\\Downloads\\Areas_in_blore.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c03590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#File check module\n",
    "file_location = r'C:\\Users\\JeevaNithi\\Downloads\\zomato'\n",
    "print(file_location)\n",
    "files_for_DQ = []\n",
    "for filename in os.listdir(file_location):\n",
    "    #print(filename ,os.stat(file_location).st_size,os.stat(filename).st_size)\n",
    "    if os.stat(file_location).st_size == 0:# only consider if the file contains any data\n",
    "        print(filename + \": invalid to check DQ\")\n",
    "    else:\n",
    "        file_ext = filename.rsplit('_',1)[-1].rsplit('.',1)[-1]\n",
    "        print(file_ext)\n",
    "        if file_ext != 'csv': # skip the files that are not in .csv format\n",
    "            print(file_ext+\": invalid to check DQ\")\n",
    "        else:\n",
    "            # process the .csv files\n",
    "            date = (filename.rsplit('_',1)[-1].rsplit('.',1)[0])\n",
    "            d = datetime.strptime(date, \"%Y%m%d%H%M%S\").date()\n",
    "            datecheck = datetime.today() + relativedelta(months=-6) \n",
    "            datecheck = datecheck.strftime('%Y-%m-%d')\n",
    "            if str(d) >= datecheck:#extract date from file name and take file if it in the prescribed window(taken a time frame of 6 months for POC purpose)\n",
    "                print(filename)\n",
    "                files_for_DQ.append(file_location+\"\\\\\"+filename)\n",
    "            else:\n",
    "                print(filename+\" invalid to check DQ\")\n",
    "                print(files_for_DQ) #contains list of file names that are eligible for processing\n",
    "                #DQ check module\n",
    "            for file in files_for_DQ:\n",
    "                print(file)\n",
    "                df = pd.read_csv(file)\n",
    "                x=pd.DataFrame()\n",
    "                x[['contact number 1', 'contact number 2']] = df['phone'].str.split('\\r\\n', 1, expand=True)#split the phone column into 2 contacts\n",
    "                phone = x.loc[:, x.columns.str.contains('contact')].apply(lambda x: x.str.strip()).apply(lambda x: x.str.replace('+','',regex=True)) #strip the number and remove + symbol\n",
    "                df=pd.concat([df, phone], axis=1)\n",
    "                df['address'] = df['address'].str.replace(r'[^a-zA-Z0-9.,/]+',' ',regex=True) #remove special characters in address\n",
    "                df['reviews_list'] = df['reviews_list'].str.replace(r'\\s+|\\\\n', ' ', regex=True) #remove special characts in reviews\n",
    "                df['reviews_list'] = df['reviews_list'].str.replace(r'[^a-zA-Z0-9.,/\\'\\\"]+',' ',regex=True)\n",
    "                #Invalid order check\n",
    "                invalid_df = df[(df['address'].isna()) | (df['location'].isna()) & (df['phone'].isna())] #consider if address or location and phone number missing records as invalid orders\n",
    "                if os.path.isdir(file_location +\"\\output\"):\n",
    "                    output_path = file_location +\"\\output\"+ \"\\\\\" #if output folder is present will be stored there\n",
    "                else:\n",
    "                    output_path = file_location + \"\\\\\" #if output folder not present will be stored in the same location as the input file\n",
    "                \n",
    "                #output_path = file_location + \"\\\\\"\n",
    "                print(output_path + filename +\".bad\") #store the invalid records as .bad\n",
    "                invalid_df.to_csv(output_path + filename +\".bad\")\n",
    "                \n",
    "                #Invalid Phone number check\n",
    "                invalid_phone = df[(df['phone'].isna())]\n",
    "                invalid_phone.to_csv(output_path + filename +\".bad_phone\") #for testing purpose stroring invalid phone records as .bad_phone\n",
    "                #null records\n",
    "                null = df[df.isnull().any(axis=1)]\n",
    "                #clean reccords\n",
    "                clean = df.dropna()\n",
    "                clean.to_csv(output_path + filename  + \".out\") #storing not null records as clean .out files\n",
    "                \n",
    "else:\n",
    "    print(\"No files Found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "06d60e5f3e77757675cf1e3fe0a471476ea088cff45131fa90e1a95bb8dbe014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
